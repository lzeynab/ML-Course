{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7bGk48l2XK5r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# difference = remove_items(list_a, items_to_remove)\n",
        "def remove_items_slow(list_a, items_to_remove):\n",
        "    if (len(list_a) == 0):\n",
        "        return []\n",
        "    first = list_a[0]\n",
        "    rest = list_a[1:]\n",
        "    next_result = remove_items_slow(rest, items_to_remove)\n",
        "    if (first in items_to_remove):\n",
        "        return next_result\n",
        "    else:\n",
        "        return [first] + next_result\n",
        "\n",
        "\n",
        "def remove_items_iter(list_a, items_to_remove, result):\n",
        "    if (len(list_a) == 0):\n",
        "        return result\n",
        "    first = list_a[0]\n",
        "    rest = list_a[1:]\n",
        "    if (first in items_to_remove):\n",
        "        return remove_items_iter(rest, items_to_remove, result)\n",
        "    else:\n",
        "        return remove_items_iter(rest, items_to_remove, result + [first])\n",
        "\n",
        "\n",
        "# difference = remove_items(list_a, items_to_remove)\n",
        "def remove_items(list_a, items_to_remove):\n",
        "    return remove_items_iter(list_a, items_to_remove, [])\n",
        "\n",
        "\n",
        "\n",
        "# remapped_labels = remap_class_labels(classes)\n",
        "def remap_class_labels(labels, classes):\n",
        "    max_class = np.max(classes)\n",
        "    new_indices = np.zeros((max_class+1))\n",
        "    for i in range(0, max_class+1):\n",
        "        if (i in classes):\n",
        "            new_indices[i] = classes.index(i)\n",
        "\n",
        "    remapped_labels = np.zeros((len(labels)))\n",
        "    for i in range(0, len(labels)):\n",
        "        label = labels[i]\n",
        "        remapped_labels[i] = new_indices[label]\n",
        "\n",
        "    return remapped_labels\n",
        "\n",
        "\n",
        "#(selected_inputs, selected_labels) = select_classes(inputs, labels, classes)\n",
        "# inputs are expected to be of shape (num_objects, ...)\n",
        "def select_classes(inputs, labels, classes):\n",
        "    number = inputs.shape[0]\n",
        "    indices = np.zeros((number), dtype='bool')\n",
        "    for c in classes:\n",
        "        c_indices = (labels == c)\n",
        "        indices = np.logical_or(indices, c_indices)\n",
        "\n",
        "    selected_inputs = inputs[indices]\n",
        "    selected_labels = labels[indices]\n",
        "    remapped_labels = remap_class_labels(selected_labels, classes)\n",
        "    return (selected_inputs, remapped_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "B75ELj8uXaDY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = keras.datasets.mnist\n",
        "#dataset = keras.datasets.fashion_mnist\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(train_inputs, train_labels), (test_inputs, test_labels) = dataset.load_data()\n",
        "number_of_classes = np.max([np.max(train_labels), np.max(test_labels)]) + 1\n",
        "input_shape = train_inputs[0].shape\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "train_inputs = train_inputs.astype(\"float32\") / 255\n",
        "test_inputs = test_inputs.astype(\"float32\") / 255\n",
        "\n",
        "# Right now, train_inputs[i] (for any i) is a 28x28 2D array.\n",
        "# The Conv2D layer requires each input to be a 3D array.\n",
        "# We use the np.expand_dims function to convert each training input to\n",
        "# a 3D array of shape (28, 28, 1), to make it compatible with the Conv2D layer.\n",
        "train_inputs = np.expand_dims(train_inputs, -1)\n",
        "test_inputs = np.expand_dims(test_inputs, -1)\n",
        "\n",
        "print(\"x_train shape:\", train_inputs.shape)\n",
        "print(train_inputs.shape[0], \"train samples\")\n",
        "print(test_inputs.shape[0], \"test samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zky7mWcWZk-Q",
        "outputId": "2222aef0-5bbb-4469-a179-a39cf509c149"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Create \"big\" dataset and \"small\" dataset\n",
        "\n",
        "original_train_inputs = train_inputs\n",
        "original_train_labels = train_labels\n",
        "original_test_inputs = test_inputs\n",
        "original_test_labels = test_labels\n",
        "\n",
        "# compile list of classes. For the MNIST dataset, this will give us a\n",
        "# list of 10 class labels, from 0 to 9.\n",
        "original_classes = list(np.union1d(np.unique(train_labels), np.unique(test_labels)))\n",
        "\n",
        "# We will exclude all samples of \"small classes\" from the big training dataset.\n",
        "#small_classes = [2,3]\n",
        "small_classes = [1,3,5,7,9]\n",
        "big_classes = remove_items(original_classes, small_classes)\n",
        "\n",
        "(big_train_inputs, big_train_labels) = select_classes(original_train_inputs,\n",
        "                                                      original_train_labels,\n",
        "                                                      big_classes)\n",
        "\n",
        "(big_test_inputs, big_test_labels) = select_classes(original_test_inputs,\n",
        "                                                    original_test_labels,\n",
        "                                                    big_classes)\n",
        "\n",
        "(small_train_inputs, small_train_labels) = select_classes(original_train_inputs,\n",
        "                                                          original_train_labels,\n",
        "                                                          small_classes)\n",
        "\n",
        "(small_test_inputs, small_test_labels) = select_classes(original_test_inputs,\n",
        "                                                        original_test_labels,\n",
        "                                                        small_classes)\n",
        "\n",
        "#%%\n",
        "\n",
        "temp = small_train_inputs\n",
        "(num, _, _, _) = temp.shape\n",
        "temp = np.repeat(temp, 3, axis=3)\n",
        "small_train_inputs = np.zeros((num,32,32,3))\n",
        "small_train_inputs[:,2:30,2:30,:] = temp\n",
        "\n",
        "temp = small_test_inputs\n",
        "(num, _, _, _) = temp.shape\n",
        "temp = np.repeat(temp, 3, axis=3)\n",
        "small_test_inputs = np.zeros((num,32,32,3))\n",
        "small_test_inputs[:,2:30,2:30,:] = temp\n",
        "\n",
        "#%%\n",
        "\n",
        "input_shape = small_train_inputs[0].shape\n",
        "vgg16 = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=input_shape)\n",
        "\n",
        "small_num_classes = len(small_classes)\n",
        "\n",
        "# This is where we use the Sequential API to create the model.\n",
        "# Notice that we create a list of layers, where we use all layers of the\n",
        "# model except for the last one, and we add a new fully connected\n",
        "# output layer.\n",
        "refined_model = keras.Sequential([keras.Input(shape=input_shape)]+\n",
        "                                 vgg16.layers +\n",
        "                                 [layers.Flatten(),\n",
        "                                  layers.Dropout(0.5),\n",
        "                                  layers.Dense(512, activation=\"tanh\"),\n",
        "                                  layers.Dropout(0.5),\n",
        "                                  layers.Dense(small_num_classes, activation=\"softmax\")])\n",
        "\n",
        "# We freeze the weights of all layers except the ones in the (new) output layer.\n",
        "for i in range(0, len(vgg16.layers)):\n",
        "    refined_model.layers[i].trainable = False\n",
        "\n",
        "\n",
        "refined_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "refined_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7adKMZoXZqjg",
        "outputId": "4a85062d-2486-47ee-cf05-0f23d2a3ad23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        multiple                  0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14979909 (57.14 MB)\n",
            "Trainable params: 265221 (1.01 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model (essentially, train the weights of the last layer) on the\n",
        "# \"small\" dataset.\n",
        "train_size = 100  # this specifies the size of the \"small\" training set\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "hist_1dense = refined_model.fit(small_train_inputs[0:train_size],\n",
        "                  small_train_labels[0:train_size],\n",
        "                  epochs=epochs, batch_size=batch_size,\n",
        "#                  validation_data = (small_test_inputs, small_test_labels)\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgrmKL5FZ5fs",
        "outputId": "9cc92df0-6712-46b4-9353-f97d518a349a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 2s 57ms/step - loss: 1.8750 - accuracy: 0.3700\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 1.1475 - accuracy: 0.5700\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.8822 - accuracy: 0.6900\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.8162 - accuracy: 0.7200\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.7198 - accuracy: 0.7300\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 2s 82ms/step - loss: 0.6423 - accuracy: 0.7300\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.5976 - accuracy: 0.8300\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.6295 - accuracy: 0.7800\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.5458 - accuracy: 0.8200\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.4311 - accuracy: 0.8100\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5573 - accuracy: 0.7800\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.4264 - accuracy: 0.8500\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.3378 - accuracy: 0.9000\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 2s 64ms/step - loss: 0.4815 - accuracy: 0.8300\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.4094 - accuracy: 0.8200\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.4827 - accuracy: 0.8600\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.5385 - accuracy: 0.8200\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.3958 - accuracy: 0.8500\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.4479 - accuracy: 0.8500\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.4132 - accuracy: 0.8300\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3157 - accuracy: 0.9000\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2844 - accuracy: 0.9000\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 2s 82ms/step - loss: 0.3102 - accuracy: 0.8900\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.3697 - accuracy: 0.8400\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.4120 - accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3853 - accuracy: 0.8500\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2959 - accuracy: 0.8700\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2383 - accuracy: 0.9000\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.2726 - accuracy: 0.9000\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2842 - accuracy: 0.8900\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 2s 64ms/step - loss: 0.2508 - accuracy: 0.8900\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.2798 - accuracy: 0.8900\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.3615 - accuracy: 0.8400\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2444 - accuracy: 0.9000\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3373 - accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2248 - accuracy: 0.9100\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.2611 - accuracy: 0.8900\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3025 - accuracy: 0.9000\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2135 - accuracy: 0.9200\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.2108 - accuracy: 0.9200\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 2s 83ms/step - loss: 0.1712 - accuracy: 0.9500\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2420 - accuracy: 0.9100\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3321 - accuracy: 0.8700\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2820 - accuracy: 0.9100\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2132 - accuracy: 0.9000\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.2004 - accuracy: 0.9000\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3801 - accuracy: 0.8800\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 0.2616 - accuracy: 0.8700\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.2503 - accuracy: 0.9300\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.1831 - accuracy: 0.9200\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.1557 - accuracy: 0.9300\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.2313 - accuracy: 0.8900\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3096 - accuracy: 0.9000\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2372 - accuracy: 0.9100\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3442 - accuracy: 0.8800\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2154 - accuracy: 0.9200\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 2s 88ms/step - loss: 0.2145 - accuracy: 0.9200\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.1803 - accuracy: 0.9400\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.2480 - accuracy: 0.9300\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2899 - accuracy: 0.8900\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.1421 - accuracy: 0.9400\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.2099 - accuracy: 0.9200\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2931 - accuracy: 0.9000\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.2372 - accuracy: 0.9200\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 2s 75ms/step - loss: 0.2577 - accuracy: 0.9100\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.2334 - accuracy: 0.9100\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2377 - accuracy: 0.9000\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2441 - accuracy: 0.9000\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3323 - accuracy: 0.8600\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.2196 - accuracy: 0.9200\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2031 - accuracy: 0.9300\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3131 - accuracy: 0.8900\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 2s 66ms/step - loss: 0.2051 - accuracy: 0.9200\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 2s 89ms/step - loss: 0.3058 - accuracy: 0.8500\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.1428 - accuracy: 0.9600\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2085 - accuracy: 0.9000\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.2049 - accuracy: 0.9300\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.1715 - accuracy: 0.9400\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.1670 - accuracy: 0.9400\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2093 - accuracy: 0.9400\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2058 - accuracy: 0.9200\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 2s 83ms/step - loss: 0.3037 - accuracy: 0.8900\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.2658 - accuracy: 0.8900\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.1225 - accuracy: 0.9800\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.1557 - accuracy: 0.9400\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3046 - accuracy: 0.8700\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2648 - accuracy: 0.8700\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.0970 - accuracy: 0.9800\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.1998 - accuracy: 0.9300\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 2s 68ms/step - loss: 0.1779 - accuracy: 0.9400\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.1454 - accuracy: 0.9300\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.1431 - accuracy: 0.9300\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.1399 - accuracy: 0.9500\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2386 - accuracy: 0.9000\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.1479 - accuracy: 0.9500\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.2071 - accuracy: 0.9100\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2910 - accuracy: 0.9100\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3527 - accuracy: 0.8700\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 2s 88ms/step - loss: 0.1942 - accuracy: 0.9200\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 2s 76ms/step - loss: 0.1281 - accuracy: 0.9600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = refined_model.evaluate(small_test_inputs, small_test_labels, verbose=2)\n",
        "print('\\nTest accuracy: %.2f' % (test_acc * 100))\n",
        "#refined_model.save('fashion_mnist_refined5_tsize20_epochs100.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkjqb_wAaxqh",
        "outputId": "e27c147f-0727-495e-daed-a3cffd3fbed6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159/159 - 54s - loss: 0.4986 - accuracy: 0.8504 - 54s/epoch - 337ms/step\n",
            "\n",
            "Test accuracy: 85.04\n"
          ]
        }
      ]
    }
  ]
}